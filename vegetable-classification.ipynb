{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir('/kaggle/input/vegetable-image-dataset/Vegetable Images/'))\n\n# for dirname, _, filenames in os.walk('/kaggle/input/kaggle/input/vegetable-image-dataset/Vegetable Images/'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T13:10:18.239643Z","iopub.execute_input":"2022-05-19T13:10:18.239891Z","iopub.status.idle":"2022-05-19T13:10:18.254538Z","shell.execute_reply.started":"2022-05-19T13:10:18.239866Z","shell.execute_reply":"2022-05-19T13:10:18.253644Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:18.302663Z","iopub.execute_input":"2022-05-19T13:10:18.302909Z","iopub.status.idle":"2022-05-19T13:10:23.939924Z","shell.execute_reply.started":"2022-05-19T13:10:18.302882Z","shell.execute_reply":"2022-05-19T13:10:23.938927Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimg_height = 180\nimg_width = 180\ndata_dir = '/kaggle/input/vegetable-image-dataset/Vegetable Images/'","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:23.941631Z","iopub.execute_input":"2022-05-19T13:10:23.942372Z","iopub.status.idle":"2022-05-19T13:10:23.946565Z","shell.execute_reply.started":"2022-05-19T13:10:23.942336Z","shell.execute_reply":"2022-05-19T13:10:23.945661Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir+'/train',\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:23.947971Z","iopub.execute_input":"2022-05-19T13:10:23.948396Z","iopub.status.idle":"2022-05-19T13:10:26.580441Z","shell.execute_reply.started":"2022-05-19T13:10:23.948367Z","shell.execute_reply":"2022-05-19T13:10:26.579766Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir+'/validation',\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:26.581984Z","iopub.execute_input":"2022-05-19T13:10:26.582641Z","iopub.status.idle":"2022-05-19T13:10:26.920288Z","shell.execute_reply.started":"2022-05-19T13:10:26.582603Z","shell.execute_reply":"2022-05-19T13:10:26.919631Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:26.921666Z","iopub.execute_input":"2022-05-19T13:10:26.922116Z","iopub.status.idle":"2022-05-19T13:10:26.927664Z","shell.execute_reply.started":"2022-05-19T13:10:26.922075Z","shell.execute_reply":"2022-05-19T13:10:26.926825Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:26.929359Z","iopub.execute_input":"2022-05-19T13:10:26.930033Z","iopub.status.idle":"2022-05-19T13:10:28.653642Z","shell.execute_reply.started":"2022-05-19T13:10:26.929917Z","shell.execute_reply":"2022-05-19T13:10:28.652652Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"normalization_layer = tf.keras.layers.Rescaling(1./255)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:28.654737Z","iopub.execute_input":"2022-05-19T13:10:28.654997Z","iopub.status.idle":"2022-05-19T13:10:28.679924Z","shell.execute_reply.started":"2022-05-19T13:10:28.654964Z","shell.execute_reply":"2022-05-19T13:10:28.679261Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\n# Notice the pixel values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:28.681276Z","iopub.execute_input":"2022-05-19T13:10:28.681721Z","iopub.status.idle":"2022-05-19T13:10:28.913512Z","shell.execute_reply.started":"2022-05-19T13:10:28.681689Z","shell.execute_reply":"2022-05-19T13:10:28.912598Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"num_classes = 15\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1./255),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:28.914723Z","iopub.execute_input":"2022-05-19T13:10:28.914938Z","iopub.status.idle":"2022-05-19T13:10:28.942445Z","shell.execute_reply.started":"2022-05-19T13:10:28.914911Z","shell.execute_reply":"2022-05-19T13:10:28.941543Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:28.944751Z","iopub.execute_input":"2022-05-19T13:10:28.944998Z","iopub.status.idle":"2022-05-19T13:10:28.965311Z","shell.execute_reply.started":"2022-05-19T13:10:28.944968Z","shell.execute_reply":"2022-05-19T13:10:28.964640Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=3\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:10:28.966252Z","iopub.execute_input":"2022-05-19T13:10:28.966929Z","iopub.status.idle":"2022-05-19T13:17:38.895432Z","shell.execute_reply.started":"2022-05-19T13:10:28.966890Z","shell.execute_reply":"2022-05-19T13:17:38.894732Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(3)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:17:38.896438Z","iopub.execute_input":"2022-05-19T13:17:38.896691Z","iopub.status.idle":"2022-05-19T13:17:39.203919Z","shell.execute_reply.started":"2022-05-19T13:17:38.896662Z","shell.execute_reply":"2022-05-19T13:17:39.203086Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"image_url = \"https://www.healthifyme.com/blog/wp-content/uploads/2020/01/capsicum-cover-1.jpg\"\nimage_path = tf.keras.utils.get_file('/kaggle/working/Vegetable1.jpg', origin=image_url,cache_dir=None,cache_subdir='')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:39:58.472062Z","iopub.execute_input":"2022-05-19T13:39:58.472596Z","iopub.status.idle":"2022-05-19T13:39:59.894208Z","shell.execute_reply.started":"2022-05-19T13:39:58.472560Z","shell.execute_reply":"2022-05-19T13:39:59.893368Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"img = tf.keras.utils.load_img(\n    image_path, target_size=(img_height, img_width)\n)\nimg_array = tf.keras.utils.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:40:01.172208Z","iopub.execute_input":"2022-05-19T13:40:01.172497Z","iopub.status.idle":"2022-05-19T13:40:01.255837Z","shell.execute_reply.started":"2022-05-19T13:40:01.172452Z","shell.execute_reply":"2022-05-19T13:40:01.254920Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model.save('my_model.h5')\n# Install helper packages:\n!pip install tf2onnx onnx onnxruntime\n\n# Load model from .h5 and save as Saved Model:\nimport tensorflow as tf\nmodel = tf.keras.models.load_model(\"my_model.h5\")\ntf.saved_model.save(model, \"tmp_model\")\n\n# Convert in bash:\n!python -m tf2onnx.convert --saved-model tmp_model --output \"my_model.onnx\"","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:37:47.618135Z","iopub.execute_input":"2022-05-19T13:37:47.618401Z","iopub.status.idle":"2022-05-19T13:37:55.424556Z","shell.execute_reply.started":"2022-05-19T13:37:47.618373Z","shell.execute_reply":"2022-05-19T13:37:55.423339Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"tfjs.converters.save_keras_model(model, \".\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T13:18:17.413626Z","iopub.execute_input":"2022-05-19T13:18:17.414711Z","iopub.status.idle":"2022-05-19T13:18:17.517786Z","shell.execute_reply.started":"2022-05-19T13:18:17.414666Z","shell.execute_reply":"2022-05-19T13:18:17.516780Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}